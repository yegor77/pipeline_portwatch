# ğŸ“¦ Pipeline MedalhÃ£o Portwatch â€” DocumentaÃ§Ã£o do Projeto

# Porque o projeto nasceu?

Como profissional formado em Analytics Engineering pela Indicium, minha atuaÃ§Ã£o no dia a dia Ã© focada principalmente nas etapas finais do ciclo de dados â€” modelagem, padronizaÃ§Ã£o e camadas analÃ­ticas (SZ â†’ CZ). Apesar disso, sempre tive interesse em dominar tambÃ©m o processo completo, desde a ingestÃ£o bruta atÃ© a entrega final.

Este projeto nasce justamente com esse propÃ³sito:
demonstrar minha capacidade de construir um pipeline ponta a ponta, cobrindo coleta via API, ingestÃ£o raw em formato parquet, padronizaÃ§Ã£o e validaÃ§Ã£o dos dados, arquitetura do tipo medalhÃ£o e orquestraÃ§Ã£o completa via Airflow.

AlÃ©m de servir como estudos e prÃ¡tica, ele tambÃ©m reforÃ§a meu portfÃ³lio mostrando que tenho domÃ­nio tÃ©cnico nÃ£o apenas da camada analÃ­tica, mas tambÃ©m de toda a fundaÃ§Ã£o necessÃ¡ria para que ela exista â€” incluindo ingestÃ£o, organizaÃ§Ã£o de zonas, qualidade e governanÃ§a dos dados.

## ğŸ” VisÃ£o Geral
Este projeto implementa um pipeline de dados baseado na arquitetura MedalhÃ£o (Raw â†’ Silver â†’ Gold) utilizando:

- Python
- Airflow (orquestraÃ§Ã£o)
- Formato Parquet nas trÃªs camadas
- Consumo de API (ArcGIS/ESRI â€“ Chokepoints)
- PadronizaÃ§Ã£o e validaÃ§Ã£o dos dados
- Metadados automÃ¡ticos em todas as camadas

O objetivo Ã© coletar, tratar e disponibilizar dados histÃ³ricos sobre trÃ¡fego marÃ­timo em pontos crÃ­ticos globais (â€œchokepointsâ€).

# ğŸ§± Estrutura do Projeto

/dags
â””â”€â”€ DAG_Portwatch.py

/scripts
â”œâ”€â”€ Portwatch_rz.py
â”œâ”€â”€ Portwatch_sz.py
â””â”€â”€ Portwatch_cz.py

/database
â”œâ”€â”€ RZ/
â”œâ”€â”€ SZ/
â””â”€â”€ CZ/

.gitignore
requirements.txt

# ğŸš€ Fluxo Geral do Pipeline

1. **Camada RZ (Raw Zone)**
   - Conecta na API do ArcGIS.
   - Consulta dados paginados por **ano** e **porto**.
   - Trata tipagem mÃ­nima.
   - Remove duplicaÃ§Ãµes.
   - Gera um arquivo Parquet bruto por execuÃ§Ã£o.
   - Gera metadados (.json).
   - Registra log de extraÃ§Ã£o.

2. **Camada SZ (Silver Zone)**
   - LÃª *todos os arquivos* da RZ.
   - Consolida tudo em um Ãºnico dataframe.
   - Padroniza nomes, datas e tipos.
   - Detecta inconsistÃªncias de totais.
   - Cria colunas derivadas (ex.: mÃªs-ano).
   - Gera arquivo Parquet tratado.
   - Gera metadados de qualidade.

3. **Camada CZ (Gold Zone)**
   - LÃª **apenas o arquivo mais recente da SZ**.
   - Renomeia colunas para termos analÃ­ticos.
   - Ajuste final de tipos e formataÃ§Ãµes.
   - Ordena estrutura final.
   - Exporta o arquivo Parquet Gold.
   - Gera metadados finais.

# âš™ï¸ OrquestraÃ§Ã£o â€” Airflow

# ğŸ§ª Qualidade e Confiabilidade

Cada camada gera:
- Arquivo `.parquet`
- Arquivo `.json` com metadados

Os metadados incluem:
- Datas de execuÃ§Ã£o
- Quantidade de registros
- Colunas existentes
- PerÃ­odo de datas
- InconsistÃªncias detectadas
- Arquivos de origem

# ğŸ“ˆ PossÃ­veis EvoluÃ§Ãµes

- IngestÃ£o incremental na RZ  
- Particionamento do SZ e CZ  
- PadronizaÃ§Ã£o com `pyarrow schema`  
- ValidaÃ§Ã£o com **Great Expectations**  
- ParametrizaÃ§Ã£o via Variables ou Connections do Airflow  
- InserÃ§Ã£o em banco analÃ­tico (Athena/Snowflake/BigQuery)

# ğŸ ConclusÃ£o

O projeto implementa um pipeline robusto, modular e fiel ao padrÃ£o medalhÃ£o, garantindo:

- rastreabilidade  
- consistÃªncia  
- facilidade de manutenÃ§Ã£o  
- formato analÃ­tico final para BI  

Ideal para evoluir em direÃ§Ã£o a um Data Lake mais amplo ou processos analÃ­ticos de maior escala.